{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qa_intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRWlGpYOG9aj",
        "colab_type": "text"
      },
      "source": [
        "# Question Answering Made Easy\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1mMEHcKW4bLcVTQlOGaURZ4V2q8hifYDO' />\n",
        "\n",
        "\n",
        "<!-- \n",
        "1\n",
        "<img src='https://drive.google.com/uc?export=view&id=13DuUpJVCfluOlXpM5XJHmdIXvPWDFoOw' />\n",
        "\n",
        "2\n",
        "<img src='https://drive.google.com/uc?export=view&id=1EUWWBVTl8dICEx8gtZ4ZAbSarN4fAPSg' />\n",
        "\n",
        "3\n",
        "<img src='https://drive.google.com/uc?export=view&id=1ycnPyzW7LkvOr6yF9L_maYK5rJibeL21' />\n",
        "\n",
        "4\n",
        "<img src='https://drive.google.com/uc?export=view&id=1QggrHLQDwZDae6OVPu70918aWm1wZSzM' />\n",
        "\n",
        "5\n",
        "<img src='https://drive.google.com/uc?export=view&id=1yeCvm7MTvdJBLbR08OF632i72uyZzvyP' />\n",
        "\n",
        "-->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcbkwt-KELsk",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "## Big Data, NLP\n",
        "\n",
        "<img src='https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fbernardmarr%2Ffiles%2F2018%2F05%2FAdobeStock_60784412-1200x720.jpg' />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K_zV6pGrxu9",
        "colab_type": "code",
        "outputId": "3783697c-dc11-43f6-f29d-2e676e30dffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/andresrosso/miami_talk_2019.git\n",
        "!cd miami_talk_2019;bash qa_tutorial.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'miami_talk_2019'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 33 (delta 9), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "Download word2vec embedding\n",
            "--2019-09-26 18:33:27--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.105.37\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.105.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  66.7MB/s    in 42s     \n",
            "\n",
            "2019-09-26 18:34:09 (37.5 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n",
            "Install trec_eval information retrieval evaluation tool\n",
            "./trec_eval.9.0/\n",
            "./trec_eval.9.0/m_prefs_simp_ret.c\n",
            "./trec_eval.9.0/m_prefs_pair_imp.c\n",
            "./trec_eval.9.0/m_Rprec_mult.c\n",
            "./trec_eval.9.0/m_set_F.c\n",
            "./trec_eval.9.0/meas_acc.c\n",
            "./trec_eval.9.0/bpref_bug\n",
            "./trec_eval.9.0/get_qrels_prefs.c\n",
            "./trec_eval.9.0/formats.c\n",
            "./trec_eval.9.0/m_set_P.c\n",
            "./trec_eval.9.0/m_num_rel.c\n",
            "./trec_eval.9.0/m_bpref.c\n",
            "./trec_eval.9.0/m_set_map.c\n",
            "./trec_eval.9.0/CHANGELOG\n",
            "./trec_eval.9.0/m_runid.c\n",
            "./trec_eval.9.0/m_iprec_at_recall.c\n",
            "./trec_eval.9.0/README\n",
            "./trec_eval.9.0/m_gm_map.c\n",
            "./trec_eval.9.0/m_set_recall.c\n",
            "./trec_eval.9.0/m_set_rel_P.c\n",
            "./trec_eval.9.0/common.h\n",
            "./trec_eval.9.0/m_P_avgjg.c\n",
            "./trec_eval.9.0/m_map_cut.c\n",
            "./trec_eval.9.0/m_recall.c\n",
            "./trec_eval.9.0/utility_pool.c\n",
            "./trec_eval.9.0/convert_zscores.c\n",
            "./trec_eval.9.0/m_num_rel_ret.c\n",
            "./trec_eval.9.0/m_prefs_avgjg.c\n",
            "./trec_eval.9.0/m_P.c\n",
            "./trec_eval.9.0/m_utility.c\n",
            "./trec_eval.9.0/m_map_avgjg.c\n",
            "./trec_eval.9.0/get_qrels.c\n",
            "./trec_eval.9.0/m_prefs_simp.c\n",
            "./trec_eval.9.0/m_num_q.c\n",
            "./trec_eval.9.0/m_prefs_avgjg_imp.c\n",
            "./trec_eval.9.0/m_infap.c\n",
            "./trec_eval.9.0/get_prefs.c\n",
            "./trec_eval.9.0/m_map.c\n",
            "./trec_eval.9.0/m_gm_bpref.c\n",
            "./trec_eval.9.0/m_ndcg.c\n",
            "./trec_eval.9.0/get_qrels_jg.c\n",
            "./trec_eval.9.0/m_prefs_avgjg_Rnonrel.c\n",
            "./trec_eval.9.0/trec_format.h\n",
            "./trec_eval.9.0/m_prefs_simp_imp.c\n",
            "./trec_eval.9.0/get_zscores.c\n",
            "./trec_eval.9.0/m_ndcg_cut.c\n",
            "./trec_eval.9.0/m_num_ret.c\n",
            "./trec_eval.9.0/m_binG.c\n",
            "./trec_eval.9.0/m_Rprec.c\n",
            "./trec_eval.9.0/m_prefs_pair_ret.c\n",
            "./trec_eval.9.0/form_res_rels.c\n",
            "./trec_eval.9.0/meas_print_single.c\n",
            "./trec_eval.9.0/m_rel_P.c\n",
            "./trec_eval.9.0/get_trec_results.c\n",
            "./trec_eval.9.0/m_prefs_num_prefs_poss.c\n",
            "./trec_eval.9.0/m_11pt_avg.c\n",
            "./trec_eval.9.0/m_prefs_pair.c\n",
            "./trec_eval.9.0/Makefile\n",
            "./trec_eval.9.0/meas_avg.c\n",
            "./trec_eval.9.0/m_Rndcg.c\n",
            "./trec_eval.9.0/m_relstring.c\n",
            "./trec_eval.9.0/meas_init.c\n",
            "./trec_eval.9.0/m_Rprec_mult_avgjg.c\n",
            "./trec_eval.9.0/m_prefs_num_prefs_ful_ret.c\n",
            "./trec_eval.9.0/m_prefs_num_prefs_ful.c\n",
            "./trec_eval.9.0/m_recip_rank.c\n",
            "./trec_eval.9.0/m_prefs_avgjg_ret.c\n",
            "./trec_eval.9.0/measures.c\n",
            "./trec_eval.9.0/meas_print_final.c\n",
            "./trec_eval.9.0/functions.h\n",
            "./trec_eval.9.0/m_success.c\n",
            "./trec_eval.9.0/m_prefs_avgjg_Rnonrel_ret.c\n",
            "./trec_eval.9.0/m_num_nonrel_judged_ret.c\n",
            "./trec_eval.9.0/form_res_rels_jg.c\n",
            "./trec_eval.9.0/m_G.c\n",
            "./trec_eval.9.0/test/\n",
            "./trec_eval.9.0/test/prefs.results.test\n",
            "./trec_eval.9.0/test/qrels.123\n",
            "./trec_eval.9.0/test/out.test.a\n",
            "./trec_eval.9.0/test/out.test.aql\n",
            "./trec_eval.9.0/test/out.test.aqZ\n",
            "./trec_eval.9.0/test/out.test.qrels_jg\n",
            "./trec_eval.9.0/test/out.test\n",
            "./trec_eval.9.0/test/out.test.prefs\n",
            "./trec_eval.9.0/test/results.trunc\n",
            "./trec_eval.9.0/test/results.test\n",
            "./trec_eval.9.0/test/out.test.aq\n",
            "./trec_eval.9.0/test/prefs.rank20\n",
            "./trec_eval.9.0/test/zscores_file~\n",
            "./trec_eval.9.0/test/out.test.qrels_prefs\n",
            "./trec_eval.9.0/test/qrels.rel_level\n",
            "./trec_eval.9.0/test/out.test.aqc\n",
            "./trec_eval.9.0/test/prefs.test\n",
            "./trec_eval.9.0/test/out.test.aqcM\n",
            "./trec_eval.9.0/test/out.test.meas_params\n",
            "./trec_eval.9.0/test/zscores_file\n",
            "./trec_eval.9.0/test/test.scr1\n",
            "./trec_eval.9.0/test/qrels.test\n",
            "./trec_eval.9.0/m_ndcg_rel.c\n",
            "./trec_eval.9.0/sysfunc.h\n",
            "./trec_eval.9.0/trec_eval.c\n",
            "./trec_eval.9.0/form_prefs_counts.c\n",
            "./trec_eval.9.0/trec_eval.h\n",
            "clang -g -I.  -Wall -DVERSIONID=\\\"9.0\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c -lm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zoULl6dP8U0",
        "colab_type": "text"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "<table bgcolor=\"#000000\">\n",
        "\n",
        "<tr>\n",
        "<td>\n",
        "<font size=\"+1\">\n",
        "\n",
        "&bull;  In the last 10 years, rapid technology development</br> has  prompted the emergence of structured, </br> semi-structured and unstructured data  [2]\n",
        "</br></br>\n",
        "&bull; Over the last two years alone 90 percent</br> of the data in the world was generated [1]\n",
        "</br></br>\n",
        "&bull;  Big data has become important for data-intensive</br>  scientific research\n",
        "\n",
        "</font>\n",
        "</td>\n",
        "<td>\n",
        "<img src='https://www.researchgate.net/profile/Dong_Liang28/publication/274233315/figure/fig5/AS:640993871282178@1529836256534/Global-growth-trend-of-data-volume-2006-2020-based-on-The-digital-universe-in-2020_W640.jpg' />\n",
        "</td>\n",
        "</tr>\n",
        "\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKET23cfLTuk",
        "colab_type": "text"
      },
      "source": [
        "## Why Automatic Question Answering?\n",
        "\n",
        "### Customer Support Chatbots\n",
        "\n",
        "<img src='https://blog.intercomassets.com/blog/wp-content/uploads/2019/02/Cleo-example.gif'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOv0ufzuqpRd",
        "colab_type": "text"
      },
      "source": [
        "### Conversational Comercial Interfaces\n",
        "\n",
        "<img src='https://www.singlegrain.com/wp-content/uploads/2018/07/Airbnb-chatbot.gif' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whf9bD_pqpUe",
        "colab_type": "text"
      },
      "source": [
        "### Automatic Information Retrieval\n",
        "\n",
        "<img src='https://images-na.ssl-images-amazon.com/images/G/01/kindle/content/GTM/XrayDictionary/Search_2x.gif' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqCfV-aWqpXQ",
        "colab_type": "text"
      },
      "source": [
        "### Scientific Passage Retrieval\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/1TNKRsrXkEMvB0727Xb0hVs_F6tmnLZjM=w1921-h842-iv1\" class=\"a-b-ta-Ua\" alt=\"Displaying qa_biomedic.gif\" aria-hidden=\"true\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os-_wwCMLTxW",
        "colab_type": "text"
      },
      "source": [
        "## Question Answering Process\n",
        "\n",
        "<img src='https://lh3.google.com/u/0/d/1B-pkVPva0DJGSbrT8rI4kz4PeglWqRl3=w1921-h842-iv1' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCP-3btsPwOD",
        "colab_type": "text"
      },
      "source": [
        "## Passage Retrieval\n",
        "\n",
        "Once we have retrieve the most related documents, we will start to analyze in deep each of the document passages and rank them.\n",
        "\n",
        "The passage retrieval process is depicted in the following graph.\n",
        "\n",
        "<img src=\"https://lh3.google.com/u/0/d/1xH5NJYKuHNwlLTo3uY304drLrfZWWB-Q=w1921-h842-iv1\" class=\"a-b-ta-Ua\" alt=\"Displaying passage_retreival_process.png\" aria-hidden=\"true\">\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. Preprocessing\n",
        "2. Representation\n",
        "3. Training\n",
        "4. Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Canr5sHrqpaP",
        "colab_type": "text"
      },
      "source": [
        "# Coding a QA System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puKChTucLT0D",
        "colab_type": "text"
      },
      "source": [
        "### Objective\n",
        "\n",
        "Train a Question-Answering that can identify a semantic related sentence.\n",
        "\n",
        "<img src='https://rajpurkar.github.io/mlx/qa-and-squad/example-squad.png' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAEypcIFyvV1",
        "colab_type": "text"
      },
      "source": [
        "### The DataSet\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=13DuUpJVCfluOlXpM5XJHmdIXvPWDFoOw' />\n",
        "\n",
        "<br>\n",
        "\n",
        "#### WikiQA DataSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OMGyPzOyyct",
        "colab_type": "text"
      },
      "source": [
        "Wiki QA: is a dataset released in 2015 by Microsoft Research Group [5].\n",
        "\n",
        "Contains  Question-Answer  pairs  for  open  domain.  \n",
        "\n",
        "The  Microsoft  research group collected Bing Search Engine query logs and extract the questions the user submit from May of 2010 to July of 2011.\n",
        "\n",
        "Answers are sentences of Wikipedia summary page.\n",
        "\n",
        "\n",
        "|Split|   #Questions| #Pairs|\n",
        "| ---- |:------:| -----:|\n",
        "|TRAIN|2,118 |20,358|\n",
        "|DEV|296|2,716|\n",
        "|TEST|633|6,156|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64QHxvG3cJt",
        "colab_type": "code",
        "outputId": "d4fef1c2-6033-4cc1-a2f4-73aa95ae67b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!head -10 miami_talk_2019/WikiQACorpus/WikiQASent-train.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how are glacier caves formed ?\tA partly submerged glacier cave on Perito Moreno Glacier .\t0\n",
            "how are glacier caves formed ?\tThe ice facade is approximately 60 m high\t0\n",
            "how are glacier caves formed ?\tIce formations in the Titlis glacier cave\t0\n",
            "how are glacier caves formed ?\tA glacier cave is a cave formed within the ice of a glacier .\t1\n",
            "how are glacier caves formed ?\tGlacier caves are often called ice caves , but this term is properly used to describe bedrock caves that contain year-round ice .\t0\n",
            "How are the directions of the velocity and force vectors related in a circular motion\tIn physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path .\t0\n",
            "How are the directions of the velocity and force vectors related in a circular motion\tIt can be uniform , with constant angular rate of rotation ( and constant speed ) , or non-uniform with a changing rate of rotation .\t0\n",
            "How are the directions of the velocity and force vectors related in a circular motion\tThe rotation around a fixed axis of a three-dimensional body involves circular motion of its parts .\t0\n",
            "How are the directions of the velocity and force vectors related in a circular motion\tThe equations of motion describe the movement of the center of mass of a body .\t0\n",
            "How are the directions of the velocity and force vectors related in a circular motion\tExamples of circular motion include : an artificial satellite orbiting the Earth at constant height , a stone which is tied to a rope and is being swung in circles , a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism .\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4e94ad3e-202a-410f-dcde-851163668163",
        "id": "rjtkpcPj7m5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!cat miami_talk_2019/WikiQACorpus/WikiQASent-train.txt | grep -in Monica"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "253:how old was monica lewinsky during the affair\tMonica Samille Lewinsky ( born July 23 , 1973 ) is an American woman with whom United States President Bill Clinton admitted to having had an `` improper relationship '' while she worked at the White House in 1995 and 1996 .\t1\n",
            "254:how old was monica lewinsky during the affair\tThe affair and its repercussions ( which included Clinton 's impeachment ) became known as the Lewinsky scandal .\t0\n",
            "15622:when was steven tyler born\tSteven Tyler ( born Steven Victor Tallarico ; March 26 , 1948 ) is an American singer , songwriter , and multi-instrumentalist , best known as the frontman and lead singer of the Boston -based rock band Aerosmith , in which he also plays the harmonica , and occasional piano and percussion .\t1\n",
            "16414:who was the president when benjamin franklin was alive\tHe invented the lightning rod , bifocals , the Franklin stove , a carriage odometer , and the glass 'armonica ' .\t0\n",
            "16593:what is muse 's lead singer 's name\tThe band consists of school friends Matthew Bellamy ( lead vocals , lead guitar , piano , keyboards , keytar ) , Christopher Wolstenholme ( bass , vocals , keyboards , rhythm guitar , harmonica ) and Dominic Howard ( drums , percussion , synthesisers , sampling ) .\t1\n",
            "17339:Where Is Monica Lewinsky Today\tMonica Samille Lewinsky ( born July 23 , 1973 ) is an American woman with whom United States President Bill Clinton admitted to having had an `` improper relationship '' while she worked at the White House in 1995 and 1996 .\t0\n",
            "17340:Where Is Monica Lewinsky Today\tThe affair and its repercussions ( which included Clinton 's impeachment ) became known as the Lewinsky scandal .\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY9fBbqG3c1S",
        "colab_type": "text"
      },
      "source": [
        "#### Make a DataSet Reader Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvhfdp9XYVPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "input_files = {'train': 'miami_talk_2019/WikiQACorpus/WikiQASent-train.txt',\n",
        "               'test': 'miami_talk_2019/WikiQACorpus/WikiQASent-test.txt',\n",
        "               'validate': 'miami_talk_2019/WikiQACorpus/WikiQASent-dev.txt',\n",
        "               'all': 'miami_talk_2019/WikiQACorpus/WikiQA.tsv'}\n",
        "\n",
        "'''\n",
        "Question and set of candidate answers abstraction\n",
        "'''\n",
        "class QASample:\n",
        "    question_id = None\n",
        "    document_title = None\n",
        "    question = None\n",
        "    answers = []\n",
        "    correct_answer = []\n",
        "\n",
        "    def __init__(self):\n",
        "      self.answers = []\n",
        "      self.correct_answer = []\n",
        "    \n",
        "    def __str__(self):\n",
        "        return \"Q:{} \\nA:{} \\nC#{} >> {}\".format(self.question,\n",
        "                                               str(self.answers),\n",
        "                                               str(self.correct_answer),\n",
        "                                               list(map(self.answers.__getitem__, self.correct_answer)))\n",
        "\n",
        "def load_questions_from_file(mode):\n",
        "    questions = []\n",
        "    n = 0\n",
        "\n",
        "    with open(input_files.get(mode)) as f:\n",
        "        question_text = None\n",
        "        question = None\n",
        "        parsed_questions = 0\n",
        "        answers_count = 0\n",
        "\n",
        "        for line in f:\n",
        "            split_line = line.rstrip().split('\\t')\n",
        "            # If new question (but not the first one)\n",
        "            if question_text is not None and question_text != split_line[0]:\n",
        "                is_new_question = True\n",
        "                questions.append(question)\n",
        "                parsed_questions += 1\n",
        "            else:\n",
        "                is_new_question = False\n",
        "\n",
        "            question_text = split_line[0]\n",
        "\n",
        "            # Number of samples/documents\n",
        "            n += 1\n",
        "\n",
        "            # If new question entity\n",
        "            if is_new_question or question is None:\n",
        "                answers_count = 0\n",
        "                question = QASample()\n",
        "                question.question = split_line[0]\n",
        "                question.answers.append(split_line[1])\n",
        "            else:\n",
        "                question.answers.append(split_line[1])\n",
        "\n",
        "            # Add answer if found\n",
        "            if split_line[2] == \"1\":\n",
        "                question.correct_answer.append(answers_count)\n",
        "\n",
        "            answers_count += 1\n",
        "\n",
        "    return questions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ET_drpM3GhD",
        "colab_type": "text"
      },
      "source": [
        "#### Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft-7l5iiX9So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build Training dataset \n",
        "questions = {}\n",
        "questions['train'] = load_questions_from_file('train')\n",
        "questions['validate'] = load_questions_from_file('validate')\n",
        "questions['test'] = load_questions_from_file('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a3c8bedc-aebf-40e2-c530-33400bed160e",
        "id": "iKbMgWZj--_E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#print question 153 25\n",
        "print( questions['train'][0] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q:how are glacier caves formed ? \n",
            "A:['A partly submerged glacier cave on Perito Moreno Glacier .', 'The ice facade is approximately 60 m high', 'Ice formations in the Titlis glacier cave', 'A glacier cave is a cave formed within the ice of a glacier .', 'Glacier caves are often called ice caves , but this term is properly used to describe bedrock caves that contain year-round ice .'] \n",
            "C#[3] >> ['A glacier cave is a cave formed within the ice of a glacier .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnTfSx5-LT3X",
        "colab_type": "text"
      },
      "source": [
        "##Make data analyzable\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1EUWWBVTl8dICEx8gtZ4ZAbSarN4fAPSg' />\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOqbaYoY8nrs",
        "colab_type": "text"
      },
      "source": [
        "* **Tokenization**:  tokenization is the task of chopping it up into pieces, called tokens, perhaps at the same time throwing away certain characters, such as punctuation. Here is an example of tokenization [6].\n",
        "\n",
        "<center>\n",
        "<img src='https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56.png' width='50%' />\n",
        "</center>\n",
        "\n",
        "\n",
        "* **Stop Word Removal**: Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words . The general strategy for determining a stop list is to sort the terms by collection frequency (the total number of times each term appears in the document collection), and then to take the most frequent terms, often hand-filtered for their semantic content relative to the domain of the documents being indexed, as a stop list , the members of which are then discarded during indexing. \n",
        "\n",
        "<center>\n",
        "<img src='https://www.cdn.geeksforgeeks.org/wp-content/uploads/Stop-word-removal-using-NLTK.png' />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_VOs9Fep73x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNkcPPMgqNN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "def data_preprocess(data, remove_stop_words=False):\n",
        "    data = tokenizer.tokenize(data.lower())\n",
        "    if remove_stop_words:\n",
        "        data = [word for word in data if word not in STOPWORDS]\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3LJ2j8b7N41",
        "colab_type": "code",
        "outputId": "37b50d86-60f3-4373-e163-c5f1966b26a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_preprocess(questions['test'][50].question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'division', 'is', 'tsu', 'football']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAN4xhp616o",
        "colab_type": "code",
        "outputId": "3409ef1e-910c-4508-a467-087aeb7c9852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_preprocess(questions['test'][50].question, remove_stop_words=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['division', 'tsu', 'football']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEFbCdvkkyWG",
        "colab_type": "text"
      },
      "source": [
        "##Transform in a computer readable way  \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1ycnPyzW7LkvOr6yF9L_maYK5rJibeL21' />\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlvLcIak0xN",
        "colab_type": "text"
      },
      "source": [
        "#### Word2Vect\n",
        "\n",
        "Word2vec is a **word embedding** model created by Google in 2013, it is based on deep learning and its goal is to transform words into dense numerical vectors within a continuous vector space that captures contextual and semantic information.\n",
        "\n",
        "Most frequent words tend to have a higher magnitude [11].\n",
        "\n",
        "Essentially this model is unsupervised taking large amounts of text, creates a vocabulary of possible words and generates **dense word embeddings**. It is usually possible to define the size of the **word embedding** vectors. This makes the representation of **word embedding** more compact than that obtained from the BoW model which by nature is sparse.\n",
        "\n",
        "The fact that we can analyze words in a corpus to deduce their meaning is the fundamental idea behind distributional semantics. The huge amount of data allow is important for the “distributional hypothesis”. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llJtJTq-UH-Y",
        "colab_type": "code",
        "outputId": "e56710bc-56f1-4798-c127-c9395dc22d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import word2vec, KeyedVectors\n",
        "\n",
        "embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPePsDIlAd9I",
        "colab_type": "text"
      },
      "source": [
        "#### Semantic Relations in Vector Space\n",
        "\n",
        "\n",
        "adding the vectors associated with the words king and woman while subtracting man is equal to the vector associated with queen. This describes a gender relationship [8].\n",
        "\n",
        "<!--\n",
        "<center>\n",
        "<img src='https://miro.medium.com/max/1070/1*jJqMEK98OtuZNczwWBJELw.gif' width='50%'/>\n",
        "</center>\n",
        "-->\n",
        "\n",
        "<center>\n",
        "<img src='https://adriancolyer.files.wordpress.com/2016/04/word2vec-king-queen-composition.png?w=656&zoom=2' width='50%' />\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE_lB-SixSRG",
        "colab_type": "text"
      },
      "source": [
        "#### Cosine Similarity Representation Model\n",
        "Cosine similarity is a vector metric distance that is magnitude invariant.\n",
        "\n",
        "The similarity matrix **`M`** represents the semantic relatedness of the **`i-th`** question term and the  **j-th`** answer term according to a cosine similarity measure. \n",
        "\n",
        "Each element  **`Mij`**,is using next equation.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1J5PLYtnQTCW0a1S9FyeutD6xH8lybzG5' width='70%'/>\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xlrMIJ2HbA3",
        "colab_type": "text"
      },
      "source": [
        "##The Deep Learning Model\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1QggrHLQDwZDae6OVPu70918aWm1wZSzM' />\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "#### CNN Pattern Extraction \n",
        "\n",
        "Convolutional Neural Networks (ConvNets or CNNs) are a category of Neural Networks that have proven very effective in areas such as image recognition and classification. ConvNets have been successful in identifying faces, objects and traffic signs apart from powering vision in robots and self driving cars [13].\n",
        "\n",
        "<img src='https://glassboxmedicine.files.wordpress.com/2019/05/ezgif-4-dbcc57f60557.gif?w=371' />\n",
        "<br>\n",
        "In  the  proposed method, the CNN  receives  the  similarity  matrix M.  The  hypothesis  is  that  the model  will  be  able to  identify  term-similarity  patterns  that  help  to  determine  the  relevance  of  aquestion-answer pair. \n",
        "\n",
        "Patterns identified by the CNN are sub-sampled by a pooling layer. The output of the pooling layer feeds a fully-connected layer. Finally,the output of the model is generated by a sigmoid unit. This output correspondsto  can be interpreted as a degree of relatedness between the question **q** and the answer **a** [14].\n",
        "<br><br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=17Qv6ehMVxpKAyi7EZJr31GjSXnVH6rDE' width='80%'/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Ihb3F_HKBS",
        "colab_type": "text"
      },
      "source": [
        "#### Lets Represent Pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnR1HiXUxVFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def transform_pair(pair, return_ids = False, is_test = False):\n",
        "    return buildCosineSimMatrix(pair, is_test)\n",
        "\n",
        "def def_noword_random(word, dim=300):\n",
        "    np.random.seed(sum([ord( x )for x in word]))\n",
        "    return np.random.rand(dim)\n",
        "\n",
        "def transform2Word2Vect(sentence, def_noword_function=def_noword_random):\n",
        "    w2vect = []\n",
        "    for i in range(len(sentence)):\n",
        "        w2vect.append( w2v[sentence[i]] if sentence[i] in w2v else def_noword_function(sentence[i]) )\n",
        "    return w2vect\n",
        "    \n",
        "def buildCosineSimMatrix(pair, is_test):\n",
        "    #Build Question Answer Matrix Pairs\n",
        "    q_list = data_preprocess(pair[0])\n",
        "    q_vect = transform2Word2Vect(sentence=q_list)\n",
        "    #Answer processing\n",
        "    a_list = data_preprocess(pair[1])\n",
        "    a_vect = transform2Word2Vect(sentence=a_list)        \n",
        "    #Get cosine distance\n",
        "    cos_matrix = np.zeros((maxterms,maxterms))\n",
        "    if (len(q_vect) > 1) & (len(a_vect) > 1):\n",
        "        distance = spatial.distance.cdist(q_vect[0:maxterms], a_vect[0:maxterms], 'cosine')\n",
        "        cos_matrix = 1 - distance/2\n",
        "        shape_cos_matrix = cos_matrix.shape\n",
        "        cos_matrix = np.pad(cos_matrix, \n",
        "                        ((0, maxterms-shape_cos_matrix[0]),(0,maxterms-shape_cos_matrix[1])), \n",
        "                        mode='constant')\n",
        "    if np.isnan(cos_matrix).any():\n",
        "        print('ERROR IS NAN: ',pair)\n",
        "    if is_test:\n",
        "        return np.expand_dims(cos_matrix,-1)\n",
        "    else:\n",
        "        return np.expand_dims(cos_matrix,-1), pair[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY713ygBLT8l",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeQEUXmFsmI",
        "colab_type": "text"
      },
      "source": [
        "#### TF Data\n",
        "\n",
        "As you should know, feed-dict is the slowest possible way to pass information to TensorFlow and it must be avoided. The correct way to feed data into your models is to use an input pipeline to ensure that the GPU has never to wait for new stuff to come in.\n",
        "\n",
        "Fortunately, TensorFlow has a built-in API, called Dataset to make it easier to accomplish this task. In this tutorial, we are going to see how we can create an input pipeline using it and how to feed the data into the model efficiently.\n",
        "\n",
        "* Importing Data. Create a Dataset instance from some data\n",
        "* Create an Iterator. Using the dataset we can create an Iterator instanvce that will iterate thought the dataset\n",
        "* Consuming Data. Using the iterator we can get the real data from the dataset in order to feed the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hse33fW0USvr",
        "colab_type": "code",
        "outputId": "6c5024ee-0c53-4ee3-f71f-c58b5469058b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, GlobalMaxPool2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pon2Eez2yMIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_model():\n",
        "    inputs = Input(shape=(40, 40, 1))\n",
        "    x = Conv2D(64, (3, 3),activation='relu', padding='valid')(inputs)\n",
        "    x = GlobalMaxPool2D()(x)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77YTjmG5LT_Z",
        "colab_type": "text"
      },
      "source": [
        "#### Training Pipelie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xekc1pWhyh6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global last_was_0\n",
        "\n",
        "def data_generator(input_data, transform_pair_function, is_training, batch_size):\n",
        "    '''Construct a data generator using tf.Dataset'''\n",
        "    \n",
        "    def pair_generator():\n",
        "        last_was_0 = False\n",
        "        for i in input_data:\n",
        "            data = transform_pair_function(i)\n",
        "            x = data[0]\n",
        "            y = data[1]\n",
        "            \n",
        "            if (y == 0) & last_was_0:\n",
        "              for x in range(5):\n",
        "                data = transform_pair_function(i)\n",
        "                x = data[0]\n",
        "                y = data[1]\n",
        "                if y == 1:\n",
        "                  break\n",
        "\n",
        "            if y == 1:\n",
        "              last_was_0 = False\n",
        "            if y == 0:\n",
        "              last_was_0 = True\n",
        "\n",
        "            yield (x,y)\n",
        "    \n",
        "    def preprocess_fn(x_sample, label):\n",
        "        '''A transformation function to preprocess raw data\n",
        "        into trainable input. '''\n",
        "        return x_sample, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator( pair_generator, output_types=(tf.float32,tf.int32), \n",
        "                                             output_shapes=(tf.TensorShape((None, None, None)), tf.TensorShape(())) )\n",
        "    #from_tensor_slices(input_data)\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
        "\n",
        "    # Transform and batch data at the same time\n",
        "    dataset = dataset.apply(tf.data.experimental.map_and_batch(\n",
        "        preprocess_fn, batch_size,\n",
        "        num_parallel_batches=5,  # cpu cores\n",
        "        drop_remainder=True if is_training else False))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch( tf.data.experimental.AUTOTUNE )\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oHjwrwNytV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_pipeline(training_set, validation_set, model_name):\n",
        "  # #############\n",
        "  # Call Backs\n",
        "  # #############\n",
        "  best_model_path = model_name+'.hdf5'\n",
        "  checkpoint = ModelCheckpoint(best_model_path, \n",
        "                             monitor=\"val_loss\", \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='auto')\n",
        "  earlyStopping = EarlyStopping(monitor=\"val_loss\", \n",
        "                             patience=3, \n",
        "                             verbose=1, \n",
        "                             mode='auto')\n",
        "\n",
        "  # #############\n",
        "  # Train Model\n",
        "  # #############\n",
        "  model = keras_model()  # your keras model here sparse_categorical_crossentropy  binary_crossentropy  categorical_hinge\n",
        "  model.compile('adam', 'kullback_leibler_divergence', metrics=['accuracy'])\n",
        "  history = model.fit(\n",
        "      training_set,\n",
        "      steps_per_epoch=50,\n",
        "      epochs=_EPOCHS,\n",
        "      validation_data=validation_set,\n",
        "      validation_steps=20,\n",
        "      verbose = 2,\n",
        "      callbacks=[checkpoint, earlyStopping])\n",
        "  \n",
        "  return model, history, best_model_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOGJLdkVy3CN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_EPOCHS      = 10\n",
        "_BATCH_SIZE  = 64\n",
        "maxterms = 40\n",
        "w2v = embedding_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_dRY-dv0xe",
        "colab_type": "code",
        "outputId": "bb3d643b-014f-4e42-e152-12de97dd5c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "def buildQAPairs(dataset):\n",
        "    questions_answer_pairs = []\n",
        "    for k, test_q_k in enumerate(dataset):\n",
        "        q = test_q_k.question\n",
        "        for i, a_i in enumerate(test_q_k.answers):\n",
        "            is_correct = True if i in test_q_k.correct_answer else False\n",
        "            questions_answer_pairs += [(q, a_i, is_correct)]\n",
        "    return questions_answer_pairs\n",
        "\n",
        "training_set = buildQAPairs(questions['train'])\n",
        "validation_set = buildQAPairs(questions['validate'])\n",
        "\n",
        "# #############\n",
        "# Load Dataset\n",
        "# #############\n",
        "training_gen = data_generator(training_set, transform_pair, is_training=True, batch_size=_BATCH_SIZE)\n",
        "validation_gen = data_generator(validation_set, transform_pair, is_training=False, batch_size=_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From <ipython-input-16-2fcd4dbc77a6>:43: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqeEOakpy8QV",
        "colab_type": "code",
        "outputId": "7bac4dd4-865d-4e1f-d03f-7b8297548379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "import time\n",
        "\n",
        "t = time.process_time()\n",
        "model, history, best_model_path = training_pipeline(training_gen, validation_gen, model_name = \"COSINE_SIM_CNN\" )\n",
        "elapsed_time = time.process_time() - t\n",
        "print('Total time: {}'.format(elapsed_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00708, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 18s - loss: 0.0209 - acc: 0.1181 - val_loss: 0.0071 - val_acc: 0.0367\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00708 to 0.00086, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 15s - loss: 0.0041 - acc: 0.0469 - val_loss: 8.5822e-04 - val_acc: 0.0367\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00086 to 0.00017, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 16s - loss: 7.3678e-04 - acc: 0.0550 - val_loss: 1.7173e-04 - val_acc: 0.0367\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00017 to 0.00005, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 17s - loss: 2.2382e-04 - acc: 0.0578 - val_loss: 4.8787e-05 - val_acc: 0.0367\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00005 to 0.00002, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 16s - loss: 7.2968e-05 - acc: 0.0591 - val_loss: 2.2291e-05 - val_acc: 0.0367\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00002 to 0.00001, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 20s - loss: 3.2206e-05 - acc: 0.0444 - val_loss: 1.3787e-05 - val_acc: 0.0367\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00001 to 0.00001, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 18s - loss: 9.8393e-05 - acc: 0.0456 - val_loss: 7.2807e-06 - val_acc: 0.0367\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00001 to 0.00000, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 18s - loss: 1.3345e-05 - acc: 0.0450 - val_loss: 4.0216e-06 - val_acc: 0.0367\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 16s - loss: 9.8347e-06 - acc: 0.0562 - val_loss: 2.3063e-06 - val_acc: 0.0367\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to COSINE_SIM_CNN.hdf5\n",
            "50/50 - 16s - loss: 1.7843e-05 - acc: 0.0538 - val_loss: 1.1358e-06 - val_acc: 0.0367\n",
            "Total time: 267.965767815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxiJFOzzsET2",
        "colab_type": "code",
        "outputId": "12b5ec6e-b70e-48a2-ccf5-202f4fbb7325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Print learning history\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIikRUEiIiJp+f+MT/r4LDGAUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dsb07kCEIfY",
        "colab_type": "text"
      },
      "source": [
        "#### Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj8_9IpfEL7N",
        "colab_type": "text"
      },
      "source": [
        "* **Mean Average Precision** [10]: Mean average precision for a set of queries is the mean of the average precision scores for each query.\n",
        "<center>\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/decf93706ec7c8632fdfabe41470962101f9bcd8' /><br>\n",
        "<img src='https://image.jimcdn.com/app/cms/image/transf/dimension=359x10000:format=png/path/s665000f481e45f73/image/ied2b4a106427d328/version/1414324498/image.png' />\n",
        "</center>\n",
        "\n",
        "* **Mean Reciprocal Rank** [9]: The mean reciprocal rank is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. \n",
        "\n",
        "<center>\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/d16e3616105fd3cbad78fa61e2f60c6abb458e26' /><br>\n",
        "<img src='https://image.jimcdn.com/app/cms/image/transf/dimension=248x10000:format=png/path/s665000f481e45f73/image/i6ff26ffa90aab5fb/version/1414324417/image.png' />\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCbeVO9ezblm",
        "colab_type": "text"
      },
      "source": [
        "##Use our system in real world\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1yeCvm7MTvdJBLbR08OF632i72uyZzvyP' />\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "### Trec Eval\n",
        "\n",
        "trec_eval is the standard tool used by the TREC community for evaluating an ad hoc retrieval run, given the results file and a standard set of judged results [3,4]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0HhZuHM9p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = buildQAPairs(questions['test'])\n",
        "test_set_tf = np.asarray([ transform_pair(p, return_ids=False, is_test=True) for p in test_set ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wKrSmIlLKPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(best_model_path)\n",
        "predictions = model.predict(test_set_tf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQqojFYILF7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genTrecEvalFile(result, filename):\n",
        "    idx_pred = 0\n",
        "    idx_pred_2 = 0\n",
        "    with open(filename, 'w') as text_file:\n",
        "        for i, test_q_i in enumerate(questions['test']):\n",
        "            ans_vector = []\n",
        "            for k, a_k in enumerate(test_q_i.answers):\n",
        "                ans_vector += [predictions[idx_pred_2][0]]\n",
        "                idx_pred_2 += 1\n",
        "                #print ans_vector, predictions[idx_pred_2][0]\n",
        "            for j, a_j in enumerate(test_q_i.answers):\n",
        "                # 1 --> [1,0]\n",
        "                #label = 1 if (predictions[idx_pred][0])>0.5 else 0\n",
        "                label = predictions[idx_pred][0]/max(ans_vector)\n",
        "                str_out = str(i + 1) + ' 0 ' + str(j) + ' 0 ' + str(label) + ' 0\\n'\n",
        "                idx_pred += 1\n",
        "                text_file.write(str_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi40Jo0XXqbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genTrecEvalFile(predictions, 'predictions.rank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_b4C9AHkoT",
        "colab_type": "code",
        "outputId": "eae13cfa-c488-4d16-b12c-c1ee8aba430a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "!cd miami_talk_2019/trec_eval.9.0; ./trec_eval -c ../WikiQACorpus/WikiQA-test-filtered.ref ../../predictions.rank"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runid                 \tall\t0\n",
            "num_q                 \tall\t237\n",
            "num_ret               \tall\t2341\n",
            "num_rel               \tall\t283\n",
            "num_rel_ret           \tall\t283\n",
            "map                   \tall\t0.5555\n",
            "gm_map                \tall\t0.4279\n",
            "Rprec                 \tall\t0.3783\n",
            "bpref                 \tall\t0.3705\n",
            "recip_rank            \tall\t0.5670\n",
            "iprec_at_recall_0.00  \tall\t0.5724\n",
            "iprec_at_recall_0.10  \tall\t0.5724\n",
            "iprec_at_recall_0.20  \tall\t0.5724\n",
            "iprec_at_recall_0.30  \tall\t0.5663\n",
            "iprec_at_recall_0.40  \tall\t0.5621\n",
            "iprec_at_recall_0.50  \tall\t0.5621\n",
            "iprec_at_recall_0.60  \tall\t0.5499\n",
            "iprec_at_recall_0.70  \tall\t0.5499\n",
            "iprec_at_recall_0.80  \tall\t0.5493\n",
            "iprec_at_recall_0.90  \tall\t0.5493\n",
            "iprec_at_recall_1.00  \tall\t0.5493\n",
            "P_5                   \tall\t0.1831\n",
            "P_10                  \tall\t0.1114\n",
            "P_15                  \tall\t0.0762\n",
            "P_20                  \tall\t0.0593\n",
            "P_30                  \tall\t0.0398\n",
            "P_100                 \tall\t0.0119\n",
            "P_200                 \tall\t0.0060\n",
            "P_500                 \tall\t0.0024\n",
            "P_1000                \tall\t0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWBr8A6fFqJx",
        "colab_type": "code",
        "outputId": "9690f515-02cb-45bf-8a7c-0d6b3839fc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(questions['test'][2])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q:how a water pump works \n",
            "A:['A small , electrically powered pump', 'A large , electrically driven pump ( electropump ) for waterworks near the Hengsteysee , Germany .', 'A pump is a device that moves fluids ( liquids or gases ) , or sometimes slurries , by mechanical action .', 'Pumps can be classified into three major groups according to the method they use to move the fluid : direct lift , displacement , and gravity pumps .', 'Pumps operate by some mechanism ( typically reciprocating or rotary ) , and consume energy to perform mechanical work by moving the fluid .', 'Pumps operate via many energy sources , including manual operation , electricity , engines , or wind power .'] \n",
            "C#[4] >> ['Pumps operate by some mechanism ( typically reciprocating or rotary ) , and consume energy to perform mechanical work by moving the fluid .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7StbhnElhd",
        "colab_type": "code",
        "outputId": "7cf36634-ee3e-4d6f-e893-43b8c330d221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "!head -20 predictions.rank"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0 0 0 0.99998426 0\n",
            "1 0 1 0 0.9999572 0\n",
            "1 0 2 0 0.99997354 0\n",
            "1 0 3 0 0.99995935 0\n",
            "1 0 4 0 0.99988616 0\n",
            "1 0 5 0 1.0 0\n",
            "2 0 0 0 0.99999344 0\n",
            "2 0 1 0 0.9999845 0\n",
            "2 0 2 0 0.99998784 0\n",
            "2 0 3 0 0.99998593 0\n",
            "2 0 4 0 0.99997646 0\n",
            "2 0 5 0 0.99998194 0\n",
            "2 0 6 0 0.9999176 0\n",
            "2 0 7 0 0.9999997 0\n",
            "2 0 8 0 0.99998856 0\n",
            "2 0 9 0 1.0 0\n",
            "2 0 10 0 0.9999393 0\n",
            "3 0 0 0 0.99996483 0\n",
            "3 0 1 0 0.9999838 0\n",
            "3 0 2 0 1.0 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScWsL5vZEwN0",
        "colab_type": "code",
        "outputId": "f1fb2826-35cb-4df7-9afd-cb58ea220eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "!head -20 miami_talk_2019/WikiQACorpus/WikiQA-test-filtered.ref"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0 0 0\n",
            "1 0 1 0\n",
            "1 0 2 0\n",
            "1 0 3 0\n",
            "1 0 4 0\n",
            "1 0 5 1\n",
            "3 0 0 0\n",
            "3 0 1 0\n",
            "3 0 2 0\n",
            "3 0 3 0\n",
            "3 0 4 1\n",
            "3 0 5 0\n",
            "4 0 0 0\n",
            "4 0 1 0\n",
            "4 0 2 0\n",
            "4 0 3 1\n",
            "4 0 4 0\n",
            "5 0 0 0\n",
            "5 0 1 1\n",
            "5 0 2 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ro__kM11sm",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1RRSuhjzVG6r3AdvNJ8yw42Do-NvXzhQJ' width='80%'/>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shel-aFJLUCR",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] How Much Data Do We Create Every Day? The Mind-Blowing Stats Everyone Should Read  https://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read/#4530a0e060ba\n",
        "\n",
        "[2] Scientific big data and Digital Earth https://www.researchgate.net/publication/274233315_Scientific_big_data_and_Digital_Earth\n",
        "\n",
        "[3] trec_eval: information retrieval evaluation tool https://trec.nist.gov/trec_eval/\n",
        "\n",
        "[4] trec_eval: calculating scores for evaluation of information retrieval https://zipfslaw.org/2016/02/19/trec_eval-calculating-scores-for-evaluation-of-information-retrieval/\n",
        "\n",
        "[5] WikiQA dataset Yang, Y., Yih, W.t., Meek, C.: Wikiqa: A challenge dataset for open-domain ques-tion answering. In: EMNLP. vol. 1, pp. 2013–2018 (2015)\n",
        "\n",
        "[6] NLTK Tokenization https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
        "\n",
        "[7] Stop-word removal https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html\n",
        "\n",
        "[8] Queen King word2vec example https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\n",
        "\n",
        "[9] Mean Reciprocal Rank https://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
        "\n",
        "[10] Mean Average Precision https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision\n",
        "\n",
        "[11] Wilson, B. J., & Schakel, A. M. (2015). Controlled experiments for word embeddings. arXiv preprint arXiv:1510.02675.\n",
        "\n",
        "[12] Convolutions information https://denizyuret.github.io/Knet.jl/latest/cnn/\n",
        "\n",
        "[13] Convultions motivation https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\n",
        "\n",
        "[14] Rosso-Mateus, A., González, F. A., & Montes-y-Gómez, M. (2017, November). A Two-Step Neural Network Approach to Passage Retrieval for Open Domain Question Answering. In Iberoamerican Congress on Pattern Recognition (pp. 566-574). Springer, Cham."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3CSKcoL-YO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}